Methodology ‚Äì Fraud Detection with Highly Imbalanced Data
=========================================================

1\. X·ª≠ l√Ω m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng Cost-Sensitive Learning
-----------------------------------------------------------

Trong b√†i to√°n ph√°t hi·ªán gian l·∫≠n th·∫ª t√≠n d·ª•ng, d·ªØ li·ªáu c√≥ t√≠nh **m·∫•t c√¢n b·∫±ng nghi√™m tr·ªçng**, trong ƒë√≥ s·ªë l∆∞·ª£ng giao d·ªãch Fraud chi·∫øm t·ª∑ l·ªá r·∫•t nh·ªè so v·ªõi giao d·ªãch Normal.

Thay v√¨ s·ª≠ d·ª•ng c√°c ph∆∞∆°ng ph√°p **resampling** nh∆∞:

*   **SMOTE** (t·∫°o d·ªØ li·ªáu Fraud gi·∫£ c√≥ th·ªÉ g√¢y nhi·ªÖu),
    
*   ho·∫∑c **Undersampling** (lo·∫°i b·ªè d·ªØ li·ªáu th·∫≠t),
    

ph∆∞∆°ng ph√°p n√†y l·ª±a ch·ªçn **Cost-Sensitive Learning**, t·ª©c l√† **ƒëi·ªÅu ch·ªânh tr·ªçng s·ªë sai s·ªë tr·ª±c ti·∫øp trong thu·∫≠t to√°n h·ªçc**.

### C√°ch th·ª±c hi·ªán

Trong qu√° tr√¨nh hu·∫•n luy·ªán:

*   T·ª∑ l·ªá m·∫•t c√¢n b·∫±ng ƒë∆∞·ª£c t√≠nh nh∆∞ sau:
    

scale\_pos\_weight\=#Normal#Fraudscale\\\_pos\\\_weight = \\frac{\\#Normal}{\\#Fraud}scale\_pos\_weight\=#Fraud#Normal‚Äã

*   Tham s·ªë n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng trong:
    
    *   `scale_pos_weight` ƒë·ªëi v·ªõi **XGBoost** v√† **LightGBM**
        
    *   `auto_class_weights='Balanced'` ƒë·ªëi v·ªõi **CatBoost**
        

### Nguy√™n l√Ω ho·∫°t ƒë·ªông

Vi·ªác g√°n tr·ªçng s·ªë l√†m thay ƒë·ªïi **h√†m m·∫•t m√°t (loss function)**:

*   M√¥ h√¨nh s·∫Ω b·ªã **ph·∫°t n·∫∑ng h∆°n r·∫•t nhi·ªÅu** n·∫øu d·ª± ƒëo√°n sai m·ªôt giao d·ªãch Fraud
    
*   So v·ªõi d·ª± ƒëo√°n sai m·ªôt giao d·ªãch Normal
    

Nh·ªù ƒë√≥:

*   M√¥ h√¨nh bu·ªôc ph·∫£i ch√∫ √Ω ƒë·∫øn l·ªõp thi·ªÉu s·ªë
    
*   Kh√¥ng l√†m m√©o ph√¢n ph·ªëi d·ªØ li·ªáu g·ªëc
    
*   Tr√°nh r·ªßi ro sinh ra c√°c giao d·ªãch Fraud ‚Äúkh√¥ng t·ªìn t·∫°i‚Äù nh∆∞ SMOTE
    

* * *

2\. Ensemble Learning ‚Äì Voting Classifier (Soft Voting)
-------------------------------------------------------

### ƒê·ªông c∆°

M·ªôt m√¥ h√¨nh ƒë∆°n l·∫ª d·ªÖ g·∫∑p c√°c v·∫•n ƒë·ªÅ:

*   Nh·∫°y v·ªõi nhi·ªÖu
    
*   Overfitting
    
*   B√°o ƒë·ªông gi·∫£ (False Positive) ·ªü c√°c tr∆∞·ªùng h·ª£p bi√™n
    

ƒê·ªÉ kh·∫Øc ph·ª•c, h·ªá th·ªëng s·ª≠ d·ª•ng **Ensemble Learning** b·∫±ng c√°ch k·∫øt h·ª£p ba thu·∫≠t to√°n Gradient Boosting m·∫°nh nh·∫•t hi·ªán nay:

*   **XGBoost**
    
*   **LightGBM**
    
*   **CatBoost**
    

### C∆° ch·∫ø Soft Voting

*   M·ªói m√¥ h√¨nh d·ª± ƒëo√°n **x√°c su·∫•t Fraud** cho m·ªôt giao d·ªãch
    
    *   V√≠ d·ª•: XGB = 0.7, LGBM = 0.6, CatBoost = 0.8
        
*   Voting Classifier t√≠nh **trung b√¨nh x√°c su·∫•t**:
    

(0.7+0.6+0.8)/3\=0.7(0.7 + 0.6 + 0.8) / 3 = 0.7(0.7+0.6+0.8)/3\=0.7

### T√°c d·ª•ng

*   Gi·∫£m **variance (ph∆∞∆°ng sai)** c·ªßa m√¥ h√¨nh
    
*   N·∫øu m·ªôt m√¥ h√¨nh d·ª± ƒëo√°n sai (False Positive), c√°c m√¥ h√¨nh c√≤n l·∫°i c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh l·∫°i quy·∫øt ƒë·ªãnh cu·ªëi
    
*   Gi√∫p tƒÉng **ƒë·ªô ·ªïn ƒë·ªãnh** v√† **Precision**, ƒë·∫∑c bi·ªát quan tr·ªçng trong fraud detection
    

* * *

3\. Feature Engineering d·ª±a tr√™n h√†nh vi ng∆∞·ªùi d√πng
---------------------------------------------------

### L√Ω do

Fraud kh√¥ng ƒë∆∞·ª£c x√°c ƒë·ªãnh b·ªüi gi√° tr·ªã tuy·ªát ƒë·ªëi, m√† b·ªüi **m·ª©c ƒë·ªô b·∫•t th∆∞·ªùng so v·ªõi h√†nh vi b√¨nh th∆∞·ªùng c·ªßa ng∆∞·ªùi d√πng v√† ng·ªØ c·∫£nh giao d·ªãch**.  
Do ƒë√≥, h·ªá th·ªëng t·∫≠p trung x√¢y d·ª±ng c√°c **behavioral features** thay v√¨ ch·ªâ d√πng d·ªØ li·ªáu th√¥.

### C√°c ƒë·∫∑c tr∆∞ng ch√≠nh

#### 3.1 `amt_zscore`

*   ƒêo l∆∞·ªùng m·ª©c ƒë·ªô b·∫•t th∆∞·ªùng c·ªßa s·ªë ti·ªÅn giao d·ªãch so v·ªõi **l·ªãch s·ª≠ chi ti√™u c·ªßa ch√≠nh ch·ªß th·∫ª**
    
*   V√≠ d·ª•:
    
    *   Ng∆∞·ªùi th∆∞·ªùng chi ti√™u ~$50 ‚Üí giao d·ªãch $500 l√† b·∫•t th∆∞·ªùng (fraud)
        
    *   Ng∆∞·ªùi th∆∞·ªùng chi ti√™u ~$1000 ‚Üí giao d·ªãch $500 l√† b√¨nh th∆∞·ªùng
        

Z-score gi√∫p chu·∫©n h√≥a h√†nh vi chi ti√™u theo t·ª´ng ng∆∞·ªùi d√πng, thay v√¨ d√πng ng∆∞·ª°ng c·ªë ƒë·ªãnh.

* * *

#### 3.2 `distance_km`

*   T√≠nh kho·∫£ng c√°ch ƒë·ªãa l√Ω gi·ªØa:
    
    *   V·ªã tr√≠ ng∆∞·ªùi d√πng
        
    *   V·ªã tr√≠ merchant
        
*   Gian l·∫≠n th∆∞·ªùng x·∫£y ra:
    
    *   ·ªû xa v·ªã tr√≠ quen thu·ªôc
        
    *   Ho·∫∑c c√≥ s·ª± di chuy·ªÉn ƒë·ªãa l√Ω b·∫•t h·ª£p l√Ω trong th·ªùi gian ng·∫Øn
        

* * *

#### 3.3 Contextual Aggregation Features

*   So s√°nh s·ªë ti·ªÅn giao d·ªãch v·ªõi:
    
    *   Trung b√¨nh theo **category**
        
*   V√≠ d·ª•:
    
    *   Giao d·ªãch t·∫°p h√≥a v·ªõi s·ªë ti·ªÅn r·∫•t l·ªõn ‚Üí b·∫•t th∆∞·ªùng
        

C√°c ƒë·∫∑c tr∆∞ng n√†y gi√∫p m√¥ h√¨nh h·ªçc **ng·ªØ c·∫£nh ti√™u d√πng**, kh√¥ng ch·ªâ h·ªçc con s·ªë.

* * *

4\. T·ªëi ∆∞u Threshold (Decision Threshold Optimization)
------------------------------------------------------

### V·∫•n ƒë·ªÅ v·ªõi threshold m·∫∑c ƒë·ªãnh

M·∫∑c ƒë·ªãnh, `model.predict()` s·ª≠ d·ª•ng ng∆∞·ª°ng x√°c su·∫•t **0.5**, tuy nhi√™n:

*   V·ªõi d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng, ng∆∞·ª°ng n√†y **kh√¥ng t·ªëi ∆∞u**
    
*   D·ªÖ g√¢y nhi·ªÅu False Positive ho·∫∑c b·ªè s√≥t Fraud
    

### C√°ch th·ª±c hi·ªán

*   H√†m `find_optimal_threshold`:
    
    *   Duy·ªát to√†n b·ªô ng∆∞·ª°ng t·ª´ 0 ‚Üí 1
        
    *   D·ª±a tr√™n **Precision‚ÄìRecall Curve**
        
*   M·ª•c ti√™u:
    
    *   T√¨m ng∆∞·ª°ng t·ªëi ∆∞u sao cho **F1-score ƒë·∫°t cao nh·∫•t**
        

### √ù nghƒ©a th·ª±c t·∫ø

V√≠ d·ª•:

*   Threshold t·ªëi ∆∞u = 0.8  
    ‚Üí M√¥ h√¨nh ch·ªâ b√°o Fraud khi ƒë·ªô ch·∫Øc ch·∫Øn > 80%  
    ‚Üí Gi·∫£m ƒë√°ng k·ªÉ **False Positive (kh√≥a th·∫ª nh·∫ßm)**
    

* * *

5\. ƒê√°nh gi√° m√¥ h√¨nh (Model Evaluation)
---------------------------------------

### Ch·ªâ s·ªë s·ª≠ d·ª•ng

*   Precision
    
*   Recall
    
*   F1-score
    
*   **PR-AUC** (quan tr·ªçng h∆°n ROC-AUC trong b√†i to√°n imbalance)
    

### C√°ch ƒë·ªçc Confusion Matrix

*   **False Positive (g√≥c tr√™n b√™n ph·∫£i)**  
    ‚Üí C·∫ßn th·∫•p ƒë·ªÉ tr√°nh kh√≥a nh·∫ßm th·∫ª kh√°ch h√†ng
    
*   **True Positive (g√≥c d∆∞·ªõi b√™n ph·∫£i)**  
    ‚Üí C·∫ßn cao ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c gian l·∫≠n th·∫≠t
    

PR-AUC > 0.8 v·ªõi d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng ƒë∆∞·ª£c xem l√† **m√¥ h√¨nh r·∫•t t·ªët**.

* * *

6\. Data Sanitization (L√†m s·∫°ch d·ªØ li·ªáu k·ªπ thu·∫≠t)
-------------------------------------------------

Trong b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω, t√™n c·ªôt ƒë∆∞·ª£c chu·∫©n h√≥a b·∫±ng c√°ch lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát:

python

Copy code

`df = df.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))`

### M·ª•c ƒë√≠ch

*   LightGBM l∆∞u c·∫•u tr√∫c c√¢y d∆∞·ªõi d·∫°ng JSON
    
*   T√™n c·ªôt ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát c√≥ th·ªÉ g√¢y l·ªói
    
*   B∆∞·ªõc n√†y ƒë·∫£m b·∫£o **t√≠nh ·ªïn ƒë·ªãnh k·ªπ thu·∫≠t** cho pipeline hu·∫•n luy·ªán
    

* * *

7\. T·ªïng k·∫øt
------------

H·ªá th·ªëng s·ª≠ d·ª•ng m·ªôt ki·∫øn tr√∫c **Hybrid** k·∫øt h·ª£p:

> \*\*Cost-Sensitive Learning

*   Boosting Ensemble (XGB, LGBM, CatBoost)
    
*   Behavioral Feature Engineering
    
*   Threshold Optimization\*\*
    

Ph∆∞∆°ng ph√°p n√†y:

*   Kh√¥ng sinh d·ªØ li·ªáu gi·∫£
    
*   Ph·∫£n √°nh ƒë√∫ng h√†nh vi th·ª±c t·∫ø
    
*   Gi·∫£m False Positive
    
*   Ph√π h·ª£p tri·ªÉn khai trong m√¥i tr∆∞·ªùng production
    

üëâ ƒê√¢y l√† **ph∆∞∆°ng ph√°p ch√≠nh c·ªßa d·ª± √°n**, kh√¥ng ph·∫£i th·ª≠ nghi·ªám ph·ª•.‚Äù